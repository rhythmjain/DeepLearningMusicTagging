{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e1d0717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f269f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb94593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26f5b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a58fb134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2175d16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80c7df6",
   "metadata": {},
   "source": [
    "# Defining Dataseat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "494e5fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicDataset(torch.utils.data.Dataset):   \n",
    "    def __init__(self, np_file_paths, labels, seq_len=10000):\n",
    "        self.seq_len = seq_len\n",
    "        self.files = np_file_paths\n",
    "        self.padder = torch.zeros(96, seq_len)\n",
    "        self.labels = labels\n",
    "#         self.labels = []\n",
    "#         for i in range(len(self.files)):\n",
    "#             label = np.random.randint(0, 10, size=15)\n",
    "#             label[label > 8] = 0\n",
    "#             label[label >= 1] = 1\n",
    "#             self.labels.append(label)\n",
    "#         for i in range(len(self.files)):\n",
    "#             label = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "#             self.labels.append(label)\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         return (self.X[index:index+self.seq_len], self.y[index+self.seq_len-1])\n",
    "    def __getitem__(self, index):\n",
    "        x = np.load(self.files[index])\n",
    "        x = torch.from_numpy(x).float()\n",
    "        x = x[:,:self.seq_len]\n",
    "        x = pad_sequence([x.T, self.padder.T], padding_value=-90, batch_first=True)[0].T\n",
    "        x = x.unsqueeze(0)\n",
    "#         input,label_ids,label\n",
    "        item = {\"input\": x, \"label_ids\":[index], \"labels\": torch.tensor(self.labels[index])}\n",
    "        return item\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b81fdb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c432a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4db4f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import disable_caching\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816b8124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c28a081",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = ['00/1164200.mp3',\n",
    " '00/12100.mp3',\n",
    " '00/1295900.mp3',\n",
    " '00/985000.mp3',\n",
    " '00/1398500.mp3',\n",
    " '00/1210700.mp3',\n",
    " '00/818600.mp3',\n",
    " '00/1339600.mp3',\n",
    " '00/506100.mp3',\n",
    " '00/390000.mp3',\n",
    " '00/16000.mp3',\n",
    " '00/1052800.mp3',\n",
    " '00/699100.mp3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5968b1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_files = ['01/16101.mp3',\n",
    " '01/1052801.mp3',\n",
    " '01/12101.mp3',\n",
    " '01/1121101.mp3',\n",
    " '01/986601.mp3',\n",
    " '01/1125001.mp3',\n",
    " '01/1086601.mp3',\n",
    " '01/1219101.mp3',\n",
    " '01/759301.mp3',\n",
    " '01/1018801.mp3',\n",
    " '01/824301.mp3',\n",
    " '01/1167301.mp3',\n",
    " '01/1380601.mp3',\n",
    " '01/661601.mp3',\n",
    " '01/1398501.mp3',\n",
    " '01/390001.mp3',\n",
    " '01/80501.mp3',\n",
    " '01/1125401.mp3',\n",
    " '01/399201.mp3',\n",
    " '01/1210701.mp3',\n",
    " '01/554901.mp3',\n",
    " '01/292501.mp3',\n",
    " '01/842401.mp3',\n",
    " '01/1157701.mp3',\n",
    " '01/1245901.mp3',\n",
    " '01/1062501.mp3',\n",
    " '01/1189901.mp3',\n",
    " '01/1398801.mp3',\n",
    " '01/1357701.mp3',\n",
    " '01/1164201.mp3',\n",
    " '01/1396501.mp3',\n",
    " '01/1304001.mp3',\n",
    " '01/913701.mp3',\n",
    " '01/718301.mp3',\n",
    " '01/1381001.mp3',\n",
    " '01/1264201.mp3',\n",
    " '01/361701.mp3',\n",
    " '01/1420701.mp3',\n",
    " '01/1406401.mp3',\n",
    " '01/708401.mp3',\n",
    " '01/1009701.mp3',\n",
    " '01/846501.mp3',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b668f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_to_labels(files):\n",
    "    col_names = ['TRACK_ID',\n",
    "     'ARTIST_ID',\n",
    "     'ALBUM_ID',\n",
    "     'PATH',\n",
    "     'DURATION',\n",
    "     'TAGS',\n",
    "     'TAGS2',\n",
    "     'TAGS3',\n",
    "     'TAGS4',\n",
    "     'TAGS5',\n",
    "     'TAGS6',\n",
    "     'TAGS7',\n",
    "     'TAGS8',\n",
    "     'TAGS9']\n",
    "    MOODPATH = \"/mnt/c/Users/aag12/Downloads/autotagging_moodtheme.tsv.txt\"\n",
    "    df = pd.read_csv(MOODPATH, sep='\\t', names=col_names)\n",
    "    df = df[df[\"PATH\"].isin(files)]\n",
    "    inds = {'fast': 0,\n",
    "     'sexy': 1,\n",
    "     'mellow': 2,\n",
    "     'heavy': 3,\n",
    "     'horror': 4,\n",
    "     'travel': 5,\n",
    "     'holiday': 6,\n",
    "     'groovy': 7,\n",
    "     'funny': 8,\n",
    "     'retro': 9,\n",
    "     'hopeful': 10,\n",
    "     'powerful': 11,\n",
    "     'cool': 12,\n",
    "     'nature': 13,\n",
    "     'game': 14}\n",
    "\n",
    "    final_labels = []\n",
    "    for i in range(len(df)):\n",
    "        curr = np.zeros(len(inds))\n",
    "        moods = list(df.iloc[i])[5:]\n",
    "        for theme in moods:\n",
    "            if type(theme) == str and \"mood\" in theme:\n",
    "                check = theme.split(\"---\")[-1]\n",
    "                if check in inds:\n",
    "                    curr[inds[check]] = 1\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        final_labels.append(curr)\n",
    "    return final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07d2d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = files_to_labels(good_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d874d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = files_to_labels(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "545d632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_np_files = [(\"/mnt/c/Users/aag12/Documents/subset_moodtheme/\" + g).replace(\".mp3\", \".npy\") for g in good_files]\n",
    "test_np_files = [(\"/mnt/c/Users/aag12/Documents/subset_moodtheme/\" + g).replace(\".mp3\", \".npy\") for g in test_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd90cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "284ea16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEQ_LEN = 10000\n",
    "SEQ_LEN = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50166183",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MusicDataset(train_np_files, train_labels, seq_len=SEQ_LEN)\n",
    "test_dataset = MusicDataset(test_np_files, test_labels, seq_len=SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a40ea85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73fff0d2",
   "metadata": {},
   "source": [
    "# MODEL TESTING\n",
    "run dataset stuff first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09379376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 96, 1000])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = train_dataset[0]['input']\n",
    "# inp = inp.unsqueeze(0)\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4e1844",
   "metadata": {},
   "source": [
    "### Structure we want\n",
    "\n",
    "* downsample with CNN\n",
    "* feed into transformer\n",
    "* feed into linear layer\n",
    "* profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c9b8c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 96, 1000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b27b5fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 334])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(1, 1, kernel_size=5, stride=3,padding=2)\n",
    "cout = conv(inp)\n",
    "cout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91b7c20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 320])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape so its function of 16\n",
    "cout = cout[:,:,:320]\n",
    "cout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d86163a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be269ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 40, 256])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put into patches\n",
    "patched = rearrange(cout, 'b (h s1) (w s2) -> b (h w) (s1 s2)', s1=patch_size, s2=patch_size)\n",
    "patched.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3e938cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patcher(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        x = x[:,:,:320]\n",
    "        return rearrange(x, 'b (h s1) (w s2) -> b (h w) (s1 s2)', s1=patch_size, s2=patch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a21dc0",
   "metadata": {},
   "source": [
    "Copying from:  https://n8henrie.com/2021/08/writing-a-transformer-classifier-in-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac2132bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(d_model=256, nhead=1)\n",
    "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "640d2dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 40, 256])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transed = transformer_encoder(patched)\n",
    "transed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "462d2825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 40, 256])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_norm = nn.LayerNorm(256)\n",
    "layered = layer_norm(transed)\n",
    "layered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27519286",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = layered[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4dc1727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertPooler(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(hidden_size, hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
    "        # to the first token.\n",
    "        first_token_tensor = hidden_states[:, 0]\n",
    "        pooled_output = self.dense(first_token_tensor)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f45ff213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp = BertPooler(256)\n",
    "bp(layered).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "028d05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lined = nn.Linear(256, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b7de6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lined(first).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b985cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = nn.Dropout(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a434f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5f59604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 334])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b506eaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6236a2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10688])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Flatten()(conv(inp)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "572a71ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = nn.Sequential(\n",
    "    conv,\n",
    "    Flatten()\n",
    "#     Patcher(),\n",
    "#     transformer_encoder,\n",
    "#     layer_norm,\n",
    "#     bp,\n",
    "#     drop,\n",
    "#     lined\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eba77499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10688])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod(inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e8523bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb4d95cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7675e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heads = [nn.Sequential(nn.Linear(256, 2), nn.Sigmoid()) for i in range(15)]\n",
    "heads = [nn.Sequential(nn.Linear(10688, 2), nn.Sigmoid()) for i in range(15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "266d4855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.0540e-06, 9.9960e-01], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heads[0](mod(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34181d5",
   "metadata": {},
   "source": [
    "## Try Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c59b309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# from transformers import AdamW\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0125ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# device = torch.device('cpu')\n",
    "device = torch.device('cuda')\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# losses = [nn.CrossEntropyLoss() for i in range(15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0dd5930b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab93a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9b1ca91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = [h.to(device) for h in heads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5662efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in heads:\n",
    "    h.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e872e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0db1273",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = train_dataset[0]['input'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "070e2ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =  train_dataset[0]['labels'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3234949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12eef92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef5e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "heads = [h.to(device) for h in heads]\n",
    "model.train()\n",
    "for h in heads:\n",
    "    h.train()\n",
    "for epoch in range(1):\n",
    "    total_loss = 0\n",
    "#     for batch in train_loader:\n",
    "    \n",
    "    for batch in train_dataset:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = batch['input'].to(device)\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        per_head_outputs = [heads[i](outputs) for i in range(15)]\n",
    "        these_losses = []\n",
    "        for i in range(15):\n",
    "            target = torch.tensor([0, 0])\n",
    "            target[int(labels[i])] = 1\n",
    "            target = target.to(device)\n",
    "#             cur_loss = losses[i](per_head_outputs[i], target.float())\n",
    "            cur_loss = criterion(per_head_outputs[i], target.float())\n",
    "            these_losses.append(cur_loss)\n",
    "#         loss = outputs[0]\n",
    "#         loss = criterion(outputs, labels)\n",
    "        loss = sum(these_losses)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        break\n",
    "    print(f\"Epoch: {epoch}; Loss: {total_loss}\")\n",
    "\n",
    "model.eval()\n",
    "for h in heads:\n",
    "    h.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44abcb75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ce5b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d9ea8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20ca89b6",
   "metadata": {},
   "source": [
    "# Defining Dataseat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef89449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicDataset(torch.utils.data.Dataset):   \n",
    "    def __init__(self, np_file_paths, labels, seq_len=10000):\n",
    "        self.seq_len = seq_len\n",
    "        self.files = np_file_paths\n",
    "        self.padder = torch.zeros(96, seq_len)\n",
    "        self.labels = labels\n",
    "#         self.labels = []\n",
    "#         for i in range(len(self.files)):\n",
    "#             label = np.random.randint(0, 10, size=15)\n",
    "#             label[label > 8] = 0\n",
    "#             label[label >= 1] = 1\n",
    "#             self.labels.append(label)\n",
    "#         for i in range(len(self.files)):\n",
    "#             label = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "#             self.labels.append(label)\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         return (self.X[index:index+self.seq_len], self.y[index+self.seq_len-1])\n",
    "    def __getitem__(self, index):\n",
    "        x = np.load(self.files[index])\n",
    "        x = torch.from_numpy(x).float()\n",
    "        x = x[:,:self.seq_len]\n",
    "        x = pad_sequence([x.T, self.padder.T], padding_value=-90, batch_first=True)[0].T\n",
    "        x = x.unsqueeze(0)\n",
    "#         input,label_ids,label\n",
    "        item = {\"input\": x, \"label_ids\":[index], \"labels\": torch.tensor(self.labels[index])}\n",
    "        return item\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8076d46f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ec0c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "498c1177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import disable_caching\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee03d7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fc8f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = ['00/1164200.mp3',\n",
    " '00/12100.mp3',\n",
    " '00/1295900.mp3',\n",
    " '00/985000.mp3',\n",
    " '00/1398500.mp3',\n",
    " '00/1210700.mp3',\n",
    " '00/818600.mp3',\n",
    " '00/1339600.mp3',\n",
    " '00/506100.mp3',\n",
    " '00/390000.mp3',\n",
    " '00/16000.mp3',\n",
    " '00/1052800.mp3',\n",
    " '00/699100.mp3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce835d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_files = ['01/16101.mp3',\n",
    " '01/1052801.mp3',\n",
    " '01/12101.mp3',\n",
    " '01/1121101.mp3',\n",
    " '01/986601.mp3',\n",
    " '01/1125001.mp3',\n",
    " '01/1086601.mp3',\n",
    " '01/1219101.mp3',\n",
    " '01/759301.mp3',\n",
    " '01/1018801.mp3',\n",
    " '01/824301.mp3',\n",
    " '01/1167301.mp3',\n",
    " '01/1380601.mp3',\n",
    " '01/661601.mp3',\n",
    " '01/1398501.mp3',\n",
    " '01/390001.mp3',\n",
    " '01/80501.mp3',\n",
    " '01/1125401.mp3',\n",
    " '01/399201.mp3',\n",
    " '01/1210701.mp3',\n",
    " '01/554901.mp3',\n",
    " '01/292501.mp3',\n",
    " '01/842401.mp3',\n",
    " '01/1157701.mp3',\n",
    " '01/1245901.mp3',\n",
    " '01/1062501.mp3',\n",
    " '01/1189901.mp3',\n",
    " '01/1398801.mp3',\n",
    " '01/1357701.mp3',\n",
    " '01/1164201.mp3',\n",
    " '01/1396501.mp3',\n",
    " '01/1304001.mp3',\n",
    " '01/913701.mp3',\n",
    " '01/718301.mp3',\n",
    " '01/1381001.mp3',\n",
    " '01/1264201.mp3',\n",
    " '01/361701.mp3',\n",
    " '01/1420701.mp3',\n",
    " '01/1406401.mp3',\n",
    " '01/708401.mp3',\n",
    " '01/1009701.mp3',\n",
    " '01/846501.mp3',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83e917cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_to_labels(files):\n",
    "    col_names = ['TRACK_ID',\n",
    "     'ARTIST_ID',\n",
    "     'ALBUM_ID',\n",
    "     'PATH',\n",
    "     'DURATION',\n",
    "     'TAGS',\n",
    "     'TAGS2',\n",
    "     'TAGS3',\n",
    "     'TAGS4',\n",
    "     'TAGS5',\n",
    "     'TAGS6',\n",
    "     'TAGS7',\n",
    "     'TAGS8',\n",
    "     'TAGS9']\n",
    "    MOODPATH = \"/mnt/c/Users/aag12/Downloads/autotagging_moodtheme.tsv.txt\"\n",
    "    df = pd.read_csv(MOODPATH, sep='\\t', names=col_names)\n",
    "    df = df[df[\"PATH\"].isin(files)]\n",
    "    inds = {'fast': 0,\n",
    "     'sexy': 1,\n",
    "     'mellow': 2,\n",
    "     'heavy': 3,\n",
    "     'horror': 4,\n",
    "     'travel': 5,\n",
    "     'holiday': 6,\n",
    "     'groovy': 7,\n",
    "     'funny': 8,\n",
    "     'retro': 9,\n",
    "     'hopeful': 10,\n",
    "     'powerful': 11,\n",
    "     'cool': 12,\n",
    "     'nature': 13,\n",
    "     'game': 14}\n",
    "\n",
    "    final_labels = []\n",
    "    for i in range(len(df)):\n",
    "        curr = np.zeros(len(inds))\n",
    "        moods = list(df.iloc[i])[5:]\n",
    "        for theme in moods:\n",
    "            if type(theme) == str and \"mood\" in theme:\n",
    "                check = theme.split(\"---\")[-1]\n",
    "                if check in inds:\n",
    "                    curr[inds[check]] = 1\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        final_labels.append(curr)\n",
    "    return final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da3e3d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = files_to_labels(good_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62f03dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = files_to_labels(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6204959",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_np_files = [(\"/mnt/c/Users/aag12/Documents/subset_moodtheme/\" + g).replace(\".mp3\", \".npy\") for g in good_files]\n",
    "test_np_files = [(\"/mnt/c/Users/aag12/Documents/subset_moodtheme/\" + g).replace(\".mp3\", \".npy\") for g in test_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ac29dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec0c2899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEQ_LEN = 10000\n",
    "SEQ_LEN = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f1dcbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MusicDataset(train_np_files, train_labels, seq_len=SEQ_LEN)\n",
    "test_dataset = MusicDataset(test_np_files, test_labels, seq_len=SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0cb9a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5d407c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb4e2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a8e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac6e554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3726e11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987f05a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
