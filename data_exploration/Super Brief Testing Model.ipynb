{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e695db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import ViTFeatureExtractor\n",
    "\n",
    "# # model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
    "# # feature_extractor = ViTFeatureExtractor.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53798d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import ViTFeatureExtractor, ViTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aaa9915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3f13d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb94593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26f5b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992793b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a58fb134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6a3fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf43be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac67a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "494e5fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicDataset(torch.utils.data.Dataset):   \n",
    "    def __init__(self, np_file_paths, labels, seq_len=10000):\n",
    "        self.seq_len = seq_len\n",
    "        self.files = np_file_paths\n",
    "        self.padder = torch.zeros(96, seq_len)\n",
    "        self.labels = labels\n",
    "#         self.labels = []\n",
    "#         for i in range(len(self.files)):\n",
    "#             label = np.random.randint(0, 10, size=15)\n",
    "#             label[label > 8] = 0\n",
    "#             label[label >= 1] = 1\n",
    "#             self.labels.append(label)\n",
    "#         for i in range(len(self.files)):\n",
    "#             label = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "#             self.labels.append(label)\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         return (self.X[index:index+self.seq_len], self.y[index+self.seq_len-1])\n",
    "    def __getitem__(self, index):\n",
    "        x = np.load(self.files[index])\n",
    "        x = torch.from_numpy(x).float()\n",
    "        x = x[:,:self.seq_len]\n",
    "        x = pad_sequence([x.T, self.padder.T], padding_value=-90, batch_first=True)[0].T\n",
    "#         input,label_ids,label\n",
    "        item = {\"input\": x, \"label_ids\":[index], \"labels\": torch.tensor(self.labels[index])}\n",
    "        return item\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b81fdb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c432a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816b8124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c28a081",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = ['00/1164200.mp3',\n",
    " '00/12100.mp3',\n",
    " '00/1295900.mp3',\n",
    " '00/985000.mp3',\n",
    " '00/1398500.mp3',\n",
    " '00/1210700.mp3',\n",
    " '00/818600.mp3',\n",
    " '00/1339600.mp3',\n",
    " '00/506100.mp3',\n",
    " '00/390000.mp3',\n",
    " '00/16000.mp3',\n",
    " '00/1052800.mp3',\n",
    " '00/699100.mp3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5968b1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_files = ['01/16101.mp3',\n",
    " '01/1052801.mp3',\n",
    " '01/12101.mp3',\n",
    " '01/1121101.mp3',\n",
    " '01/986601.mp3',\n",
    " '01/1125001.mp3',\n",
    " '01/1086601.mp3',\n",
    " '01/1219101.mp3',\n",
    " '01/759301.mp3',\n",
    " '01/1018801.mp3',\n",
    " '01/824301.mp3',\n",
    " '01/1167301.mp3',\n",
    " '01/1380601.mp3',\n",
    " '01/661601.mp3',\n",
    " '01/1398501.mp3',\n",
    " '01/390001.mp3',\n",
    " '01/80501.mp3',\n",
    " '01/1125401.mp3',\n",
    " '01/399201.mp3',\n",
    " '01/1210701.mp3',\n",
    " '01/554901.mp3',\n",
    " '01/292501.mp3',\n",
    " '01/842401.mp3',\n",
    " '01/1157701.mp3',\n",
    " '01/1245901.mp3',\n",
    " '01/1062501.mp3',\n",
    " '01/1189901.mp3',\n",
    " '01/1398801.mp3',\n",
    " '01/1357701.mp3',\n",
    " '01/1164201.mp3',\n",
    " '01/1396501.mp3',\n",
    " '01/1304001.mp3',\n",
    " '01/913701.mp3',\n",
    " '01/718301.mp3',\n",
    " '01/1381001.mp3',\n",
    " '01/1264201.mp3',\n",
    " '01/361701.mp3',\n",
    " '01/1420701.mp3',\n",
    " '01/1406401.mp3',\n",
    " '01/708401.mp3',\n",
    " '01/1009701.mp3',\n",
    " '01/846501.mp3',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b668f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_to_labels(files):\n",
    "    col_names = ['TRACK_ID',\n",
    "     'ARTIST_ID',\n",
    "     'ALBUM_ID',\n",
    "     'PATH',\n",
    "     'DURATION',\n",
    "     'TAGS',\n",
    "     'TAGS2',\n",
    "     'TAGS3',\n",
    "     'TAGS4',\n",
    "     'TAGS5',\n",
    "     'TAGS6',\n",
    "     'TAGS7',\n",
    "     'TAGS8',\n",
    "     'TAGS9']\n",
    "    MOODPATH = \"/mnt/c/Users/aag12/Downloads/autotagging_moodtheme.tsv.txt\"\n",
    "    df = pd.read_csv(MOODPATH, sep='\\t', names=col_names)\n",
    "    df = df[df[\"PATH\"].isin(files)]\n",
    "    inds = {'fast': 0,\n",
    "     'sexy': 1,\n",
    "     'mellow': 2,\n",
    "     'heavy': 3,\n",
    "     'horror': 4,\n",
    "     'travel': 5,\n",
    "     'holiday': 6,\n",
    "     'groovy': 7,\n",
    "     'funny': 8,\n",
    "     'retro': 9,\n",
    "     'hopeful': 10,\n",
    "     'powerful': 11,\n",
    "     'cool': 12,\n",
    "     'nature': 13,\n",
    "     'game': 14}\n",
    "\n",
    "    final_labels = []\n",
    "    for i in range(len(df)):\n",
    "        curr = np.zeros(len(inds))\n",
    "        moods = list(df.iloc[i])[5:]\n",
    "        for theme in moods:\n",
    "            if type(theme) == str and \"mood\" in theme:\n",
    "                check = theme.split(\"---\")[-1]\n",
    "                if check in inds:\n",
    "                    curr[inds[check]] = 1\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        final_labels.append(curr)\n",
    "    return final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07d2d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = files_to_labels(good_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d874d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = files_to_labels(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "545d632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_np_files = [(\"/mnt/c/Users/aag12/Documents/subset_moodtheme/\" + g).replace(\".mp3\", \".npy\") for g in good_files]\n",
    "test_np_files = [(\"/mnt/c/Users/aag12/Documents/subset_moodtheme/\" + g).replace(\".mp3\", \".npy\") for g in test_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd90cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "284ea16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEQ_LEN = 10000\n",
    "SEQ_LEN = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50166183",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MusicDataset(train_np_files, train_labels, seq_len=SEQ_LEN)\n",
    "test_dataset = MusicDataset(test_np_files, test_labels, seq_len=SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9374dbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 13)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fc252fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bc13be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7119fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',          # output directory\n",
    "#     num_train_epochs=3,              # total number of training epochs\n",
    "#     per_device_train_batch_size=1,  # batch size per device during training\n",
    "#     per_device_eval_batch_size=1,   # batch size for evaluation\n",
    "#     warmup_steps=10,                # number of warmup steps for learning rate scheduler\n",
    "#     weight_decay=0.01,               # strength of weight decay\n",
    "#     logging_dir='./logs',            # directory for storing logs\n",
    "#     logging_steps=10,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac61038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcefd64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7478206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "#         batch_size = x.shape[0]\n",
    "#         return x.view(batch_size, -1)\n",
    "#         return x.view(batch_size, -1)\n",
    "#         print(x.shape)\n",
    "#         print(x.flatten().shape)\n",
    "        return x.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5342545c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26e38b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "#     args=training_args,                  # training arguments, defined above\n",
    "#     train_dataset=dataset,         # training dataset\n",
    "#     eval_dataset=dataset             # evaluation dataset\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c09f5655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 1000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['input'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76567352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124bcc57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8aeb7d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# from transformers import AdamW\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7b8c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71d46879",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        Flatten(),\n",
    "        nn.Linear(96*SEQ_LEN, 512),\n",
    "        nn.ReLU(),\n",
    "#         nn.Linear(1000, 512),\n",
    "#         nn.ReLU(),\n",
    "#         nn.Linear(1024, 512),\n",
    "#         nn.Linear(512, 124),\n",
    "#         nn.Softmax(),\n",
    "#             nn.Sigmoid(),\n",
    "        )\n",
    "heads = [nn.Sequential(nn.Linear(512, 2), nn.Sigmoid()) for i in range(15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d02a5a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "losses = [nn.CrossEntropyLoss() for i in range(15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21471e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f1aaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; Loss: 411.43996238708496\n",
      "Epoch: 1; Loss: 409.0412788391113\n",
      "Epoch: 2; Loss: 409.0412788391113\n",
      "Epoch: 3; Loss: 409.0412788391113\n",
      "Epoch: 4; Loss: 409.0412788391113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten()\n",
       "  (1): Linear(in_features=96000, out_features=512, bias=True)\n",
       "  (2): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "heads = [h.to(device) for h in heads]\n",
    "model.train()\n",
    "for epoch in range(5):\n",
    "    total_loss = 0\n",
    "#     for batch in train_loader:\n",
    "        \n",
    "    for batch in train_dataset:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = batch['input'].to(device)\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        per_head_outputs = [heads[i](outputs) for i in range(15)]\n",
    "        these_losses = []\n",
    "        for i in range(15):\n",
    "            target = torch.tensor([0, 0])\n",
    "            target[int(labels[i])] = 1\n",
    "            target = target.to(device)\n",
    "            cur_loss = losses[i](per_head_outputs[i], target.float())\n",
    "            these_losses.append(cur_loss)\n",
    "#         loss = outputs[0]\n",
    "#         loss = criterion(outputs, labels)\n",
    "        loss = sum(these_losses)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch: {epoch}; Loss: {total_loss}\")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09949d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1454/3039809088.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  nn.functional.softmax(model(batch['input'].to(device))).sum()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.softmax(model(batch['input'].to(device))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c410f436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0255, -0.0454, -0.0275,  0.0358, -0.1361, -0.0021, -0.0321,  0.0438,\n",
       "         0.0119,  0.0229,  0.0430,  0.0252,  0.0128,  0.0323, -0.0048],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch['input'].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54c72c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0255, -0.0454, -0.0275,  0.0358, -0.1361, -0.0021, -0.0321,  0.0438,\n",
       "         0.0119,  0.0229,  0.0430,  0.0252,  0.0128,  0.0323, -0.0048],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch['input'].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d000dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['input'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50d9bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "#     a = model(dataset[2]['input'].to(device))\n",
    "    total_correct = 0\n",
    "    total_values = 0\n",
    "    for batch in test_dataset:\n",
    "        outputs = model(batch['input'].to(device))\n",
    "        labels = batch['labels']\n",
    "#         outputs = nn.Softmax()(outputs)\n",
    "        outputs[outputs > 0] = 1\n",
    "        outputs[outputs < 0] = 0\n",
    "        total_correct += (labels == outputs.to('cpu')).sum()\n",
    "        total_values += len(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9432cefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06666666666666667"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e36d97bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4923)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_correct / total_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc4d00e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "#     a = model(dataset[2]['input'].to(device))\n",
    "    total_correct = 0\n",
    "    total_values = 0\n",
    "    for batch in train_dataset:\n",
    "        outputs = model(batch['input'].to(device))\n",
    "        labels = batch['labels']\n",
    "#         outputs = nn.Softmax()(outputs)\n",
    "        outputs[outputs > 0] = 1\n",
    "        outputs[outputs < 0] = 0\n",
    "        total_correct += (labels == outputs.to('cpu')).sum()\n",
    "        total_values += len(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea4b7eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5127)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_correct / total_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce81144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "8255a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in train_loader:\n",
    "        inputs = batch['input'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "854d34d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "f2e4a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "663d7fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12)\n",
    "src = torch.rand((10, 32, 512))\n",
    "tgt = torch.rand((20, 32, 512))\n",
    "out = transformer_model(src, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "16350047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5214,  0.7462,  1.5416,  ...,  1.1933,  0.6153, -0.0659],\n",
       "         [-1.4950,  1.2451,  0.5920,  ..., -0.0223,  0.9517, -0.6634],\n",
       "         [-0.6652,  0.8013,  1.3819,  ...,  0.7682,  0.2696,  0.0530],\n",
       "         ...,\n",
       "         [-2.1992,  0.7358,  1.9855,  ...,  0.0718,  1.0148, -0.1242],\n",
       "         [-1.6068,  0.0923,  1.7142,  ...,  1.2601, -0.2076, -0.1038],\n",
       "         [-1.2549, -0.3516,  0.8073,  ...,  0.2366,  0.7856,  0.1373]],\n",
       "\n",
       "        [[-1.5566,  0.8384,  1.3449,  ...,  0.6766,  0.3548,  0.7389],\n",
       "         [-0.8511,  0.8868,  0.6050,  ..., -0.6807,  1.2467, -1.2463],\n",
       "         [-1.1151,  0.3095,  0.8905,  ...,  0.1912,  0.2807,  0.5792],\n",
       "         ...,\n",
       "         [-1.6557,  0.0951,  0.9750,  ...,  0.6561,  0.4272,  0.1767],\n",
       "         [-1.6226, -0.1198,  1.5999,  ...,  0.4322,  1.4955, -0.1060],\n",
       "         [-1.7911,  0.3468,  0.4423,  ...,  0.5350,  0.9664, -0.7834]],\n",
       "\n",
       "        [[-1.1344,  1.3616,  2.0517,  ...,  0.0625,  0.2578, -0.8662],\n",
       "         [-1.4028,  0.0594,  0.2899,  ...,  0.0073,  0.5746, -1.1929],\n",
       "         [-1.2505, -0.3107,  0.9866,  ..., -0.6404,  0.5107,  0.0106],\n",
       "         ...,\n",
       "         [-0.7790,  0.1102,  1.6215,  ...,  0.6152,  0.5943,  0.3665],\n",
       "         [-1.1490,  0.3525,  1.3328,  ...,  1.6729,  0.5990,  0.5350],\n",
       "         [-1.0127,  0.6717,  1.3278,  ...,  1.0252,  1.1546, -0.3536]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.8916,  1.0536,  2.0946,  ...,  0.8235,  0.4221,  0.8272],\n",
       "         [-1.3558,  0.4889,  0.7578,  ...,  1.1692,  0.2361, -0.7279],\n",
       "         [-0.9814, -0.2773,  1.3342,  ...,  0.9539,  0.5995,  0.5059],\n",
       "         ...,\n",
       "         [-1.4974,  0.4217,  1.1476,  ...,  0.7280,  0.4288,  1.1865],\n",
       "         [-1.0231,  0.8030,  1.3835,  ...,  0.9798,  0.8352, -0.5516],\n",
       "         [-1.6691,  0.6919,  0.7366,  ..., -0.4270,  1.0875,  0.3160]],\n",
       "\n",
       "        [[-1.4119,  0.7760,  2.2352,  ..., -0.1616,  0.6366, -0.1443],\n",
       "         [-0.6638,  1.2911,  0.3819,  ...,  0.4972, -0.0114, -0.5130],\n",
       "         [-1.1217,  0.7032,  0.9474,  ...,  0.3933,  1.0323,  0.1969],\n",
       "         ...,\n",
       "         [-1.7732,  0.8903,  1.7563,  ...,  0.2047,  0.8759,  0.0741],\n",
       "         [-0.8962,  0.9457,  0.6759,  ...,  0.6838,  1.3438, -0.1872],\n",
       "         [-1.8519,  0.3636,  0.9829,  ..., -0.0606,  0.9764, -0.0892]],\n",
       "\n",
       "        [[-1.5453,  1.4449,  2.1527,  ...,  0.9982,  0.2681, -0.4094],\n",
       "         [-1.0907,  0.1116,  0.8939,  ...,  0.1692, -0.0046, -0.8524],\n",
       "         [-1.7911,  1.0946,  0.8345,  ...,  0.9421,  0.5855,  0.1280],\n",
       "         ...,\n",
       "         [-0.9092,  0.5850,  1.5061,  ...,  0.3226,  1.3423,  0.3627],\n",
       "         [-1.7015,  1.0458,  1.4107,  ...,  1.3578,  0.2009, -0.0480],\n",
       "         [-2.7520, -0.4175,  1.2605,  ...,  0.3979,  1.6668, -0.2311]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3be30f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
